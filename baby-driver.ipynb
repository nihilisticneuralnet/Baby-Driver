{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12151815,"sourceType":"datasetVersion","datasetId":7653086},{"sourceId":12152039,"sourceType":"datasetVersion","datasetId":7653208},{"sourceId":12259884,"sourceType":"datasetVersion","datasetId":7725496},{"sourceId":12260005,"sourceType":"datasetVersion","datasetId":7725588}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport math\nimport time\nimport matplotlib\nmatplotlib.use('Agg')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cv2.setNumThreads(4)\n\ncap = cv2.VideoCapture(\"video.mkv\")\ninput_size = 320\n\nconfThreshold = 0.2\nnmsThreshold = 0.2\n\nfont_color = (0, 0, 255)\nfont_size = 0.5\nfont_thickness = 2\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  need to be adjusted based on video\nPIXELS_PER_METER = 4  \nFPS = 30 \nSPEED_MULTIPLIER = 6.0 ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classesFile = \"coco.names\"\nclassNames = open(classesFile).read().strip().split('\\n')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"required_class_index = [2, 3, 5, 7]\n\ndetected_classNames = []\n\nmodelConfiguration = 'yolov3-320.cfg'\nmodelWeigheights = 'yolov3-320.weights'\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeigheights)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.random.seed(42)\ncolors = np.random.randint(0, 255, size=(len(classNames), 3), dtype='uint8')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def find_center(x, y, w, h):\n    x1 = int(w / 2)\n    y1 = int(h / 2)\n    cx = x + x1\n    cy = y + y1\n    return cx, cy\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class tracker:\n    def __init__(self):\n        self.id_count = 0\n        self.center_points = {}\n        self.disappeared = {}\n        self.max_disappeared = 10\n    \n    def update(self, objects_rect):\n        if len(objects_rect) == 0:\n            for object_id in list(self.disappeared.keys()):\n                self.disappeared[object_id] += 1\n                if self.disappeared[object_id] > self.max_disappeared:\n                    self.deregister(object_id)\n            return []\n        \n        objects_bbs_ids = []\n        \n        if len(self.center_points) == 0:\n            for rect in objects_rect:\n                x, y, w, h, index = rect\n                cx = (x + x + w) // 2\n                cy = (y + y + h) // 2\n                self.center_points[self.id_count] = (cx, cy)\n                objects_bbs_ids.append([x, y, w, h, self.id_count, index])\n                self.id_count += 1\n        else:\n            input_centroids = []\n            for rect in objects_rect:\n                x, y, w, h, index = rect\n                cx = (x + x + w) // 2\n                cy = (y + y + h) // 2\n                input_centroids.append((cx, cy, x, y, w, h, index))\n            \n            object_ids = list(self.center_points.keys())\n            object_centroids = list(self.center_points.values())\n            \n            D = np.linalg.norm(np.array(object_centroids)[:, np.newaxis] - np.array([(c[0], c[1]) for c in input_centroids]), axis=2)\n            \n            rows = D.min(axis=1).argsort()\n            cols = D.argmin(axis=1)[rows]\n            \n            used_row_indices = set()\n            used_col_indices = set()\n            \n            for (row, col) in zip(rows, cols):\n                if row in used_row_indices or col in used_col_indices:\n                    continue\n                \n                if D[row, col] <= 50:  # max distance threshold\n                    object_id = object_ids[row]\n                    self.center_points[object_id] = (input_centroids[col][0], input_centroids[col][1])\n                    objects_bbs_ids.append([input_centroids[col][2], input_centroids[col][3], \n                                          input_centroids[col][4], input_centroids[col][5], \n                                          object_id, input_centroids[col][6]])\n                    \n                    used_row_indices.add(row)\n                    used_col_indices.add(col)\n                    \n                    if object_id in self.disappeared:\n                        del self.disappeared[object_id]\n            \n            unused_row_indices = set(range(0, D.shape[0])) - used_row_indices\n            unused_col_indices = set(range(0, D.shape[1])) - used_col_indices\n            \n            if D.shape[0] >= D.shape[1]:\n                for row in unused_row_indices:\n                    object_id = object_ids[row]\n                    self.disappeared[object_id] = self.disappeared.get(object_id, 0) + 1\n                    if self.disappeared[object_id] > self.max_disappeared:\n                        self.deregister(object_id)\n            else:\n                for col in unused_col_indices:\n                    cx, cy, x, y, w, h, index = input_centroids[col]\n                    self.center_points[self.id_count] = (cx, cy)\n                    objects_bbs_ids.append([x, y, w, h, self.id_count, index])\n                    self.id_count += 1\n        \n        return objects_bbs_ids\n    \n    def deregister(self, object_id):\n        del self.center_points[object_id]\n        if object_id in self.disappeared:\n            del self.disappeared[object_id]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class detect:\n    def __init__(self):\n        self.boxes = []\n        self.classIds = []\n        self.confidence_scores = []\n        self.detection = []\n        self.track = tracker()\n        self.prev_positions = {}\n        self.prev_time = {}\n        self.speed_history = {}  \n        self.position_history = {}  \n        self.frame_count = 0\n        \n    def calculate_speed_kmh(self, object_id, current_pos, current_time, frame_height):\n        if object_id not in self.prev_positions or object_id not in self.prev_time:\n            self.prev_positions[object_id] = current_pos\n            self.prev_time[object_id] = current_time\n            if object_id not in self.position_history:\n                self.position_history[object_id] = []\n            return 0\n        \n        prev_pos = self.prev_positions[object_id]\n        prev_time = self.prev_time[object_id]\n        \n        if object_id not in self.position_history:\n            self.position_history[object_id] = []\n        self.position_history[object_id].append(current_pos)\n        \n        if len(self.position_history[object_id]) > 10:\n            self.position_history[object_id] = self.position_history[object_id][-10:]\n        \n        distance_pixels = math.sqrt((current_pos[0] - prev_pos[0])**2 + (current_pos[1] - prev_pos[1])**2)\n        \n        y_position = current_pos[1]\n        perspective_factor = 1.0 + (y_position / frame_height) * 0.5 \n        distance_pixels *= perspective_factor\n        \n        time_diff = current_time - prev_time\n        \n        if time_diff <= 0 or distance_pixels < 2:  \n            return self.get_smoothed_speed(object_id, 0)\n        \n        distance_meters = distance_pixels / PIXELS_PER_METER\n        speed_ms = distance_meters / time_diff\n        speed_kmh = speed_ms * 3.6 * SPEED_MULTIPLIER\n        \n        speed_kmh = max(0, min(speed_kmh, 120))\n        \n        self.prev_positions[object_id] = current_pos\n        self.prev_time[object_id] = current_time\n        \n        return self.get_smoothed_speed(object_id, speed_kmh)\n    \n    def get_smoothed_speed(self, object_id, new_speed):\n        \"\"\"Apply heavy smoothing to reduce speed fluctuations\"\"\"\n        if object_id not in self.speed_history:\n            self.speed_history[object_id] = []\n        \n        if new_speed > 0:\n            self.speed_history[object_id].append(new_speed)\n        \n        if len(self.speed_history[object_id]) > 15:\n            self.speed_history[object_id] = self.speed_history[object_id][-15:]\n        \n        if len(self.speed_history[object_id]) == 0:\n            return 0\n        \n        speeds = self.speed_history[object_id]\n        if len(speeds) >= 3:\n            median_speed = sorted(speeds)[len(speeds)//2]\n            filtered_speeds = [s for s in speeds if abs(s - median_speed) < median_speed * 0.4]\n            if filtered_speeds:\n                speeds = filtered_speeds\n        \n        weights = [i + 1 for i in range(len(speeds))]\n        weighted_avg = sum(s * w for s, w in zip(speeds, weights)) / sum(weights)\n        \n        return weighted_avg\n        \n    def postProcess(self, outputs, img):\n        global detected_classNames\n        \n        self.boxes = []\n        self.classIds = []\n        self.confidence_scores = []\n        self.detection = []\n        \n        height, width = img.shape[:2]\n        current_time = time.time()\n        self.frame_count += 1\n\n        for output in outputs:\n            for det in output:\n                scores = det[5:]\n                self.classId = np.argmax(scores)\n                confidence = scores[self.classId]\n                if self.classId in required_class_index:\n                    if confidence > confThreshold:\n                        w, h = int(det[2] * width), int(det[3] * height)\n                        x, y = int((det[0] * width) - w / 2), int((det[1] * height) - h / 2)\n                        self.boxes.append([x, y, w, h])\n                        self.classIds.append(self.classId)\n                        self.confidence_scores.append(float(confidence))\n\n        # non-max suppression\n        if len(self.boxes) > 0:\n            indices = cv2.dnn.NMSBoxes(self.boxes, self.confidence_scores, confThreshold, nmsThreshold)\n            \n            if len(indices) > 0:\n                for i in indices.flatten():\n                    x, y, w, h = self.boxes[i][0], self.boxes[i][1], self.boxes[i][2], self.boxes[i][3]\n                    self.detection.append([x, y, w, h, required_class_index.index(self.classIds[i])])\n\n        if len(self.detection) > 0:\n            boxes_ids = self.track.update(self.detection)\n            \n            for box_id in boxes_ids:\n                x, y, w, h, object_id, index = box_id\n                \n                cx, cy = find_center(x, y, w, h)\n                \n                speed_kmh = self.calculate_speed_kmh(object_id, (cx, cy), current_time, height)\n                \n                color = [int(c) for c in colors[self.classIds[index] if index < len(self.classIds) else 0]]\n                name = classNames[self.classIds[index] if index < len(self.classIds) else 0]\n                \n                # red if > 80 km/h\n                speed_color = (0, 0, 255) if speed_kmh > 80 else (0, 255, 0)\n                \n                cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n                \n                cv2.putText(img, f'{name.upper()} {int(self.confidence_scores[index] * 100)}%' if index < len(self.confidence_scores) else f'{name.upper()}',\n                           (x, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n                \n                if speed_kmh > 10 and len(self.speed_history.get(object_id, [])) >= 3:\n                    cv2.putText(img, f\"Speed: {speed_kmh:.0f} km/h\", (x, y - 10), \n                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, speed_color, 1)\n                \n                cv2.putText(img, f\"ID: {object_id}\", (x, y + h + 20), \n                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n\n    def processVideo(self, output_path=\"video.mp4\"):\n        \"\"\"Process video and save output without displaying\"\"\"\n        global FPS, PIXELS_PER_METER\n        \n        FPS = int(cap.get(cv2.CAP_PROP_FPS))\n        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        \n        PIXELS_PER_METER = max(2, width // 400) \n        \n        new_width = int(width * 0.5)\n        new_height = int(height * 0.5)\n        \n        print(f\"Processing video: {width}x{height} -> {new_width}x{new_height}\")\n        print(f\"FPS: {FPS}, Total frames: {total_frames}\")\n        print(f\"Estimated pixels per meter: {PIXELS_PER_METER}\")\n        print(f\"Speed multiplier: {SPEED_MULTIPLIER}\")\n        print(\"Note: Adjust PIXELS_PER_METER and SPEED_MULTIPLIER if speeds seem unrealistic\")\n        \n        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n        out = cv2.VideoWriter(output_path, fourcc, FPS, (new_width, new_height))\n        \n        frame_count = 0\n        \n        try:\n            while True:\n                ret, frame = cap.read()\n                if not ret:\n                    break\n                \n                frame = cv2.resize(frame, (new_width, new_height))\n                \n                blob = cv2.dnn.blobFromImage(frame, 1 / 255, (input_size, input_size), [0, 0, 0], 1, crop=False)\n                \n                net.setInput(blob)\n                layersNames = net.getLayerNames()\n                outputNames = [layersNames[i - 1] for i in net.getUnconnectedOutLayers()]\n                outputs = net.forward(outputNames)\n                \n                self.postProcess(outputs, frame)\n                \n                out.write(frame)\n                \n                frame_count += 1\n                if frame_count % 30 == 0: \n                    print(f\"Processed {frame_count}/{total_frames} frames ({frame_count/total_frames*100:.1f}%)\")\n                \n        except Exception as e:\n            print(f\"Error during video processing: {e}\")\n        \n        finally:\n            cap.release()\n            out.release()\n            print(f\"Video processing complete! Output saved to: {output_path}\")\n            print(f\"Total frames processed: {frame_count}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detector = detect()\ndetector.processVideo(\"output.mp4\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}